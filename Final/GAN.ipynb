{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tisha\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\tisha\\anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = \"T:/CodeBase/Python/Computer Vision/MID/Project/FaceDetection/Faces/img\"\n",
    "\n",
    "GENERATE_RES = 2\n",
    "GENERATE_SQUARE = 32 * GENERATE_RES\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "PREV_ROWS = 4\n",
    "PREV_COLS = 7\n",
    "\n",
    "PREV_MARGIN = 16\n",
    "\n",
    "SEED_VAL = 100\n",
    "EPOCHS = 800\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 60000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 46.27it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "for f in tqdm(os.listdir(DATA_PATH)):\n",
    "    path = os.path.join(DATA_PATH, f)\n",
    "    image = Image.open(path).resize((GENERATE_SQUARE, GENERATE_SQUARE), Image.LANCZOS)\n",
    "    train_data.append(np.asarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.reshape(train_data, (-1, GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS))\n",
    "train_data = train_data.astype(\"float32\")\n",
    "train_data = train_data / 127.5 - 1\n",
    "\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_data).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(seed_size, channel):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(4 * 4 * 256, activation=\"relu\", input_dim=seed_size))\n",
    "    model.add(layers.Reshape((4, 4, 256)))\n",
    "\n",
    "    model.add(layers.UpSampling2D())\n",
    "    model.add(layers.Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization(momentum=0.7))\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "\n",
    "    model.add(layers.UpSampling2D())\n",
    "    model.add(layers.Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization(momentum=0.7))\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "\n",
    "    model.add(layers.UpSampling2D())\n",
    "    model.add(layers.Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization(momentum=0.7))\n",
    "    model.add(layers.Activation(\"relu\"))\n",
    "\n",
    "    if GENERATE_RES > 1:\n",
    "        model.add(layers.UpSampling2D(size=(GENERATE_RES, GENERATE_RES)))\n",
    "        model.add(layers.Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(layers.BatchNormalization(momentum=0.7))\n",
    "        model.add(layers.Activation(\"relu\"))\n",
    "\n",
    "    model.add(layers.Conv2D(channel, kernel_size=3, padding=\"same\"))\n",
    "    model.add(layers.Activation(\"tanh\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(layers.ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Conv2D(512, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = build_generator(SEED_VAL, IMAGE_CHANNELS)\n",
    "image_shape = (GENERATE_SQUARE, GENERATE_SQUARE, IMAGE_CHANNELS)\n",
    "dis = build_discriminator(image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output,fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optim = tfa.optimizers.AdamW(learning_rate=0.00001,weight_decay=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_optim = tf.keras.optimizers.Adam(learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_image(model, epoch, seed):\n",
    "    output_dir = \"T:/CodeBase/Python/Generative Adversial Network/generatedImages\"\n",
    "    p = model(seed, training=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(PREV_COLS, PREV_ROWS))\n",
    "    for i in range(p.shape[0]):\n",
    "        plt.subplot(PREV_ROWS, PREV_COLS, i+1)\n",
    "        plt.imshow((p[i] + 1) / 2) \n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig(f\"{output_dir}/img_{epoch}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, dataset, epochs, seed):\n",
    "    for epoch in range(epochs):\n",
    "        for image_batch in dataset:\n",
    "            noise = tf.random.normal([BATCH_SIZE, SEED_VAL])\n",
    "            \n",
    "            with tf.GradientTape() as dis_type:\n",
    "                real_output = discriminator(image_batch, training=True)\n",
    "                fake_images = generator(noise, training=True)\n",
    "                fake_output = discriminator(fake_images, training=True)\n",
    "                \n",
    "                dis_loss = discriminator_loss(real_output, fake_output)\n",
    "            \n",
    "            gradient_of_dis = dis_type.gradient(dis_loss, discriminator.trainable_variables)\n",
    "            dis_optim.apply_gradients(zip(gradient_of_dis, discriminator.trainable_variables))\n",
    "            \n",
    "            with tf.GradientTape() as gen_tape:\n",
    "                fake_images = generator(noise, training=True)\n",
    "                fake_output = discriminator(fake_images, training=True)\n",
    "                gen_loss = generator_loss(fake_output)\n",
    "            \n",
    "            gradient_of_gen = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "            gen_optim.apply_gradients(zip(gradient_of_gen, generator.trainable_variables))\n",
    "\n",
    "        save_generated_image(generator, epoch + 1, seed)\n",
    "        print(f\"Epoch: {epoch + 1}, Discriminator Loss: {dis_loss}, Generator Loss: {gen_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = tf.random.normal([PREV_ROWS * PREV_COLS,SEED_VAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Discriminator Loss: 2.183366060256958, Generator Loss: 0.8033819198608398\n",
      "Epoch: 2, Discriminator Loss: 1.985793948173523, Generator Loss: 0.9981874227523804\n",
      "Epoch: 3, Discriminator Loss: 1.3064777851104736, Generator Loss: 0.6026469469070435\n",
      "Epoch: 4, Discriminator Loss: 2.2795419692993164, Generator Loss: 0.8183426260948181\n",
      "Epoch: 5, Discriminator Loss: 1.088940143585205, Generator Loss: 0.8820894956588745\n",
      "Epoch: 6, Discriminator Loss: 1.433427333831787, Generator Loss: 0.8906300067901611\n",
      "Epoch: 7, Discriminator Loss: 1.48818838596344, Generator Loss: 0.6840581893920898\n",
      "Epoch: 8, Discriminator Loss: 1.7261810302734375, Generator Loss: 0.8151617646217346\n",
      "Epoch: 9, Discriminator Loss: 1.5298588275909424, Generator Loss: 0.7953641414642334\n",
      "Epoch: 10, Discriminator Loss: 1.8037075996398926, Generator Loss: 0.6401342749595642\n",
      "Epoch: 11, Discriminator Loss: 1.6053357124328613, Generator Loss: 1.028637409210205\n",
      "Epoch: 12, Discriminator Loss: 1.5065349340438843, Generator Loss: 0.8127576112747192\n",
      "Epoch: 13, Discriminator Loss: 1.2779357433319092, Generator Loss: 0.8568533658981323\n",
      "Epoch: 14, Discriminator Loss: 2.1006195545196533, Generator Loss: 0.8933429718017578\n",
      "Epoch: 15, Discriminator Loss: 1.4615594148635864, Generator Loss: 0.7032350301742554\n",
      "Epoch: 16, Discriminator Loss: 1.2081316709518433, Generator Loss: 0.9082322716712952\n",
      "Epoch: 17, Discriminator Loss: 1.5070208311080933, Generator Loss: 0.8938116431236267\n",
      "Epoch: 18, Discriminator Loss: 1.420464277267456, Generator Loss: 0.710392951965332\n",
      "Epoch: 19, Discriminator Loss: 1.2269765138626099, Generator Loss: 0.7214338779449463\n",
      "Epoch: 20, Discriminator Loss: 1.580643653869629, Generator Loss: 1.0751478672027588\n",
      "Epoch: 21, Discriminator Loss: 0.8348468542098999, Generator Loss: 0.864842414855957\n",
      "Epoch: 22, Discriminator Loss: 1.456183671951294, Generator Loss: 1.1193928718566895\n",
      "Epoch: 23, Discriminator Loss: 1.57201087474823, Generator Loss: 0.9104096293449402\n",
      "Epoch: 24, Discriminator Loss: 1.0089963674545288, Generator Loss: 0.9421806335449219\n",
      "Epoch: 25, Discriminator Loss: 1.4670199155807495, Generator Loss: 0.9148703813552856\n",
      "Epoch: 26, Discriminator Loss: 1.193182349205017, Generator Loss: 0.8917992115020752\n",
      "Epoch: 27, Discriminator Loss: 1.1968841552734375, Generator Loss: 1.1215976476669312\n",
      "Epoch: 28, Discriminator Loss: 1.292661428451538, Generator Loss: 0.998508870601654\n",
      "Epoch: 29, Discriminator Loss: 1.3118497133255005, Generator Loss: 0.8045110702514648\n",
      "Epoch: 30, Discriminator Loss: 1.0199142694473267, Generator Loss: 0.9122614860534668\n",
      "Epoch: 31, Discriminator Loss: 1.2693191766738892, Generator Loss: 1.1199188232421875\n",
      "Epoch: 32, Discriminator Loss: 1.3563179969787598, Generator Loss: 0.9013866186141968\n",
      "Epoch: 33, Discriminator Loss: 1.6656227111816406, Generator Loss: 0.9087353348731995\n",
      "Epoch: 34, Discriminator Loss: 1.6740492582321167, Generator Loss: 1.4789767265319824\n",
      "Epoch: 35, Discriminator Loss: 1.076936960220337, Generator Loss: 1.286215901374817\n",
      "Epoch: 36, Discriminator Loss: 1.3210458755493164, Generator Loss: 1.162152886390686\n",
      "Epoch: 37, Discriminator Loss: 1.0114192962646484, Generator Loss: 0.997378408908844\n",
      "Epoch: 38, Discriminator Loss: 1.3732050657272339, Generator Loss: 0.7362751960754395\n",
      "Epoch: 39, Discriminator Loss: 1.1801609992980957, Generator Loss: 1.1210049390792847\n",
      "Epoch: 40, Discriminator Loss: 1.1115448474884033, Generator Loss: 1.2033814191818237\n",
      "Epoch: 41, Discriminator Loss: 1.5259207487106323, Generator Loss: 1.2003062963485718\n",
      "Epoch: 42, Discriminator Loss: 1.434643268585205, Generator Loss: 1.0425658226013184\n",
      "Epoch: 43, Discriminator Loss: 1.202580451965332, Generator Loss: 0.9215299487113953\n",
      "Epoch: 44, Discriminator Loss: 1.0695726871490479, Generator Loss: 1.1240344047546387\n",
      "Epoch: 45, Discriminator Loss: 1.372599482536316, Generator Loss: 0.8793870806694031\n",
      "Epoch: 46, Discriminator Loss: 1.448175311088562, Generator Loss: 1.024583339691162\n",
      "Epoch: 47, Discriminator Loss: 1.0784063339233398, Generator Loss: 0.7891373634338379\n",
      "Epoch: 48, Discriminator Loss: 1.5531431436538696, Generator Loss: 1.002352237701416\n",
      "Epoch: 49, Discriminator Loss: 1.4236646890640259, Generator Loss: 1.0636457204818726\n",
      "Epoch: 50, Discriminator Loss: 0.5747752785682678, Generator Loss: 1.0544466972351074\n",
      "Epoch: 51, Discriminator Loss: 0.9501152634620667, Generator Loss: 1.1512155532836914\n",
      "Epoch: 52, Discriminator Loss: 1.6220927238464355, Generator Loss: 0.9679100513458252\n",
      "Epoch: 53, Discriminator Loss: 1.0398507118225098, Generator Loss: 1.271686315536499\n",
      "Epoch: 54, Discriminator Loss: 0.9107444286346436, Generator Loss: 0.79369056224823\n",
      "Epoch: 55, Discriminator Loss: 1.4414539337158203, Generator Loss: 1.2990297079086304\n",
      "Epoch: 56, Discriminator Loss: 1.2723922729492188, Generator Loss: 0.8866264224052429\n",
      "Epoch: 57, Discriminator Loss: 1.0784404277801514, Generator Loss: 1.0220071077346802\n",
      "Epoch: 58, Discriminator Loss: 1.0611845254898071, Generator Loss: 0.6824927926063538\n",
      "Epoch: 59, Discriminator Loss: 1.275404691696167, Generator Loss: 0.8809646368026733\n",
      "Epoch: 60, Discriminator Loss: 0.8169945478439331, Generator Loss: 1.3755404949188232\n",
      "Epoch: 61, Discriminator Loss: 0.9400634765625, Generator Loss: 0.9800562262535095\n",
      "Epoch: 62, Discriminator Loss: 0.665134608745575, Generator Loss: 1.1707038879394531\n",
      "Epoch: 63, Discriminator Loss: 0.970415472984314, Generator Loss: 1.179718017578125\n",
      "Epoch: 64, Discriminator Loss: 1.0322160720825195, Generator Loss: 0.9752863645553589\n",
      "Epoch: 65, Discriminator Loss: 0.9607224464416504, Generator Loss: 0.8890767097473145\n",
      "Epoch: 66, Discriminator Loss: 1.3244271278381348, Generator Loss: 1.0371431112289429\n",
      "Epoch: 67, Discriminator Loss: 1.1117340326309204, Generator Loss: 1.1056098937988281\n",
      "Epoch: 68, Discriminator Loss: 0.9844226837158203, Generator Loss: 1.1248515844345093\n",
      "Epoch: 69, Discriminator Loss: 1.5369250774383545, Generator Loss: 1.4200643301010132\n",
      "Epoch: 70, Discriminator Loss: 1.4356496334075928, Generator Loss: 0.8640554547309875\n",
      "Epoch: 71, Discriminator Loss: 1.3700370788574219, Generator Loss: 1.2328741550445557\n",
      "Epoch: 72, Discriminator Loss: 1.2498680353164673, Generator Loss: 1.2043249607086182\n",
      "Epoch: 73, Discriminator Loss: 1.548051357269287, Generator Loss: 0.9697786569595337\n",
      "Epoch: 74, Discriminator Loss: 0.7663400173187256, Generator Loss: 0.9817869663238525\n",
      "Epoch: 75, Discriminator Loss: 1.4800318479537964, Generator Loss: 1.0572264194488525\n",
      "Epoch: 76, Discriminator Loss: 0.9773147106170654, Generator Loss: 1.0485687255859375\n",
      "Epoch: 77, Discriminator Loss: 1.0096075534820557, Generator Loss: 1.4837400913238525\n",
      "Epoch: 78, Discriminator Loss: 1.6516363620758057, Generator Loss: 1.0464305877685547\n",
      "Epoch: 79, Discriminator Loss: 0.8993231058120728, Generator Loss: 1.0925160646438599\n",
      "Epoch: 80, Discriminator Loss: 0.7460076808929443, Generator Loss: 1.362816333770752\n",
      "Epoch: 81, Discriminator Loss: 1.517529845237732, Generator Loss: 1.2068414688110352\n",
      "Epoch: 82, Discriminator Loss: 0.8949410915374756, Generator Loss: 0.948464035987854\n",
      "Epoch: 83, Discriminator Loss: 1.1209168434143066, Generator Loss: 0.9823975563049316\n",
      "Epoch: 84, Discriminator Loss: 1.0146420001983643, Generator Loss: 1.1534242630004883\n",
      "Epoch: 85, Discriminator Loss: 1.0474755764007568, Generator Loss: 1.0785744190216064\n",
      "Epoch: 86, Discriminator Loss: 0.846983790397644, Generator Loss: 1.5790495872497559\n",
      "Epoch: 87, Discriminator Loss: 0.8527230024337769, Generator Loss: 1.4981389045715332\n",
      "Epoch: 88, Discriminator Loss: 1.0841292142868042, Generator Loss: 1.2364596128463745\n",
      "Epoch: 89, Discriminator Loss: 1.9612025022506714, Generator Loss: 0.9814157485961914\n",
      "Epoch: 90, Discriminator Loss: 0.9137669801712036, Generator Loss: 1.5869296789169312\n",
      "Epoch: 91, Discriminator Loss: 1.1874396800994873, Generator Loss: 1.1323871612548828\n",
      "Epoch: 92, Discriminator Loss: 0.8729878067970276, Generator Loss: 1.0896413326263428\n",
      "Epoch: 93, Discriminator Loss: 0.8713449835777283, Generator Loss: 1.5869495868682861\n",
      "Epoch: 94, Discriminator Loss: 1.3967961072921753, Generator Loss: 1.3348311185836792\n",
      "Epoch: 95, Discriminator Loss: 1.2923498153686523, Generator Loss: 1.114301085472107\n",
      "Epoch: 96, Discriminator Loss: 1.1294875144958496, Generator Loss: 1.2781403064727783\n",
      "Epoch: 97, Discriminator Loss: 1.0039973258972168, Generator Loss: 1.271749496459961\n",
      "Epoch: 98, Discriminator Loss: 0.7593483924865723, Generator Loss: 1.2847983837127686\n",
      "Epoch: 99, Discriminator Loss: 1.0446240901947021, Generator Loss: 1.4356224536895752\n",
      "Epoch: 100, Discriminator Loss: 0.7871599197387695, Generator Loss: 1.2619636058807373\n",
      "Epoch: 101, Discriminator Loss: 0.8801150918006897, Generator Loss: 1.2325778007507324\n",
      "Epoch: 102, Discriminator Loss: 0.6710938811302185, Generator Loss: 1.2608017921447754\n",
      "Epoch: 103, Discriminator Loss: 1.102103352546692, Generator Loss: 1.7944755554199219\n",
      "Epoch: 104, Discriminator Loss: 0.9914007186889648, Generator Loss: 1.5609380006790161\n",
      "Epoch: 105, Discriminator Loss: 1.4181973934173584, Generator Loss: 1.6140333414077759\n",
      "Epoch: 106, Discriminator Loss: 1.311305284500122, Generator Loss: 1.287226676940918\n",
      "Epoch: 107, Discriminator Loss: 0.5846216678619385, Generator Loss: 1.2760019302368164\n",
      "Epoch: 108, Discriminator Loss: 0.5794265270233154, Generator Loss: 1.8514587879180908\n",
      "Epoch: 109, Discriminator Loss: 0.8685401678085327, Generator Loss: 1.6421319246292114\n",
      "Epoch: 110, Discriminator Loss: 0.803242027759552, Generator Loss: 1.5579233169555664\n",
      "Epoch: 111, Discriminator Loss: 0.8386524319648743, Generator Loss: 1.5949888229370117\n",
      "Epoch: 112, Discriminator Loss: 0.8280102610588074, Generator Loss: 1.607690691947937\n",
      "Epoch: 113, Discriminator Loss: 0.733759880065918, Generator Loss: 1.6691749095916748\n",
      "Epoch: 114, Discriminator Loss: 0.4437485635280609, Generator Loss: 1.7737282514572144\n",
      "Epoch: 115, Discriminator Loss: 1.237439751625061, Generator Loss: 1.442815899848938\n",
      "Epoch: 116, Discriminator Loss: 0.8107529282569885, Generator Loss: 1.3071600198745728\n",
      "Epoch: 117, Discriminator Loss: 0.7455041408538818, Generator Loss: 1.4442756175994873\n",
      "Epoch: 118, Discriminator Loss: 0.8295538425445557, Generator Loss: 1.4359452724456787\n",
      "Epoch: 119, Discriminator Loss: 0.9338529706001282, Generator Loss: 1.4436545372009277\n",
      "Epoch: 120, Discriminator Loss: 0.9160425662994385, Generator Loss: 1.8005123138427734\n",
      "Epoch: 121, Discriminator Loss: 0.8359030485153198, Generator Loss: 1.3427839279174805\n",
      "Epoch: 122, Discriminator Loss: 0.7293524742126465, Generator Loss: 1.2694091796875\n",
      "Epoch: 123, Discriminator Loss: 1.088782787322998, Generator Loss: 1.0500298738479614\n",
      "Epoch: 124, Discriminator Loss: 1.0928875207901, Generator Loss: 1.1440619230270386\n",
      "Epoch: 125, Discriminator Loss: 0.8867795467376709, Generator Loss: 1.248073697090149\n",
      "Epoch: 126, Discriminator Loss: 0.8534521460533142, Generator Loss: 0.990696907043457\n",
      "Epoch: 127, Discriminator Loss: 1.0398592948913574, Generator Loss: 1.0997439622879028\n",
      "Epoch: 128, Discriminator Loss: 1.1049737930297852, Generator Loss: 1.1580469608306885\n",
      "Epoch: 129, Discriminator Loss: 0.7444208860397339, Generator Loss: 1.2882590293884277\n",
      "Epoch: 130, Discriminator Loss: 0.8903903365135193, Generator Loss: 1.1347920894622803\n",
      "Epoch: 131, Discriminator Loss: 1.0971496105194092, Generator Loss: 1.5464978218078613\n",
      "Epoch: 132, Discriminator Loss: 1.1112275123596191, Generator Loss: 1.0941294431686401\n",
      "Epoch: 133, Discriminator Loss: 0.8024483919143677, Generator Loss: 1.1919201612472534\n",
      "Epoch: 134, Discriminator Loss: 0.8721158504486084, Generator Loss: 1.4477888345718384\n",
      "Epoch: 135, Discriminator Loss: 1.0415351390838623, Generator Loss: 1.2942737340927124\n",
      "Epoch: 136, Discriminator Loss: 0.662822961807251, Generator Loss: 1.3497350215911865\n",
      "Epoch: 137, Discriminator Loss: 0.8877622485160828, Generator Loss: 0.8744088411331177\n",
      "Epoch: 138, Discriminator Loss: 0.7008121013641357, Generator Loss: 1.1373565196990967\n",
      "Epoch: 139, Discriminator Loss: 0.7916722893714905, Generator Loss: 1.2683922052383423\n",
      "Epoch: 140, Discriminator Loss: 0.8603861927986145, Generator Loss: 1.648747444152832\n",
      "Epoch: 141, Discriminator Loss: 0.9892570972442627, Generator Loss: 0.9210209846496582\n",
      "Epoch: 142, Discriminator Loss: 0.9104989767074585, Generator Loss: 1.232123851776123\n",
      "Epoch: 143, Discriminator Loss: 0.741037130355835, Generator Loss: 1.1939135789871216\n",
      "Epoch: 144, Discriminator Loss: 0.7622090578079224, Generator Loss: 1.3208084106445312\n",
      "Epoch: 145, Discriminator Loss: 0.9568970203399658, Generator Loss: 1.0655109882354736\n",
      "Epoch: 146, Discriminator Loss: 0.8264687061309814, Generator Loss: 1.017567753791809\n",
      "Epoch: 147, Discriminator Loss: 0.8317379951477051, Generator Loss: 1.1394689083099365\n",
      "Epoch: 148, Discriminator Loss: 0.9763520956039429, Generator Loss: 1.2211003303527832\n",
      "Epoch: 149, Discriminator Loss: 0.8536882996559143, Generator Loss: 1.2470917701721191\n",
      "Epoch: 150, Discriminator Loss: 1.6090911626815796, Generator Loss: 1.4054028987884521\n",
      "Epoch: 151, Discriminator Loss: 0.6705650091171265, Generator Loss: 1.4448695182800293\n",
      "Epoch: 152, Discriminator Loss: 0.7497413158416748, Generator Loss: 1.3905489444732666\n",
      "Epoch: 153, Discriminator Loss: 0.6659528017044067, Generator Loss: 1.4928011894226074\n",
      "Epoch: 154, Discriminator Loss: 0.5832932591438293, Generator Loss: 0.981654167175293\n",
      "Epoch: 155, Discriminator Loss: 0.8814926147460938, Generator Loss: 1.2398667335510254\n",
      "Epoch: 156, Discriminator Loss: 0.5340027809143066, Generator Loss: 1.5254712104797363\n",
      "Epoch: 157, Discriminator Loss: 1.0285015106201172, Generator Loss: 1.359670877456665\n",
      "Epoch: 158, Discriminator Loss: 1.2031464576721191, Generator Loss: 1.2752881050109863\n",
      "Epoch: 159, Discriminator Loss: 0.6509146094322205, Generator Loss: 1.2615399360656738\n",
      "Epoch: 160, Discriminator Loss: 0.7995530366897583, Generator Loss: 1.6807749271392822\n",
      "Epoch: 161, Discriminator Loss: 0.6591262817382812, Generator Loss: 1.6391812562942505\n",
      "Epoch: 162, Discriminator Loss: 0.6460071802139282, Generator Loss: 1.3285589218139648\n",
      "Epoch: 163, Discriminator Loss: 1.1046584844589233, Generator Loss: 1.5733650922775269\n",
      "Epoch: 164, Discriminator Loss: 0.9827437400817871, Generator Loss: 1.5065159797668457\n",
      "Epoch: 165, Discriminator Loss: 0.963627815246582, Generator Loss: 1.409807562828064\n",
      "Epoch: 166, Discriminator Loss: 1.0104296207427979, Generator Loss: 1.5202419757843018\n",
      "Epoch: 167, Discriminator Loss: 0.8059483766555786, Generator Loss: 1.31062650680542\n",
      "Epoch: 168, Discriminator Loss: 0.6787734627723694, Generator Loss: 1.3677847385406494\n",
      "Epoch: 169, Discriminator Loss: 0.8017916083335876, Generator Loss: 1.6535773277282715\n",
      "Epoch: 170, Discriminator Loss: 0.6430069804191589, Generator Loss: 1.87978994846344\n",
      "Epoch: 171, Discriminator Loss: 0.8180363774299622, Generator Loss: 1.5330076217651367\n",
      "Epoch: 172, Discriminator Loss: 0.6772505044937134, Generator Loss: 1.5816650390625\n",
      "Epoch: 173, Discriminator Loss: 0.9288296699523926, Generator Loss: 1.923834204673767\n",
      "Epoch: 174, Discriminator Loss: 0.753715991973877, Generator Loss: 1.6255534887313843\n",
      "Epoch: 175, Discriminator Loss: 0.560856819152832, Generator Loss: 1.791743278503418\n",
      "Epoch: 176, Discriminator Loss: 0.7287793159484863, Generator Loss: 1.6643364429473877\n",
      "Epoch: 177, Discriminator Loss: 0.5824801921844482, Generator Loss: 1.3883349895477295\n",
      "Epoch: 178, Discriminator Loss: 0.5876370072364807, Generator Loss: 1.4823026657104492\n",
      "Epoch: 179, Discriminator Loss: 1.0246241092681885, Generator Loss: 1.5146664381027222\n",
      "Epoch: 180, Discriminator Loss: 0.47749680280685425, Generator Loss: 2.1199724674224854\n",
      "Epoch: 181, Discriminator Loss: 0.42488741874694824, Generator Loss: 2.049659490585327\n",
      "Epoch: 182, Discriminator Loss: 0.6356860399246216, Generator Loss: 1.7108571529388428\n",
      "Epoch: 183, Discriminator Loss: 0.97943115234375, Generator Loss: 1.6907274723052979\n",
      "Epoch: 184, Discriminator Loss: 0.6424824595451355, Generator Loss: 1.5855464935302734\n",
      "Epoch: 185, Discriminator Loss: 0.66651451587677, Generator Loss: 1.397340178489685\n",
      "Epoch: 186, Discriminator Loss: 0.7417929172515869, Generator Loss: 1.8875303268432617\n",
      "Epoch: 187, Discriminator Loss: 0.5240092277526855, Generator Loss: 1.9559345245361328\n",
      "Epoch: 188, Discriminator Loss: 0.7596173286437988, Generator Loss: 1.7680835723876953\n",
      "Epoch: 189, Discriminator Loss: 1.1850563287734985, Generator Loss: 1.7163485288619995\n",
      "Epoch: 190, Discriminator Loss: 0.6804259419441223, Generator Loss: 1.7855355739593506\n",
      "Epoch: 191, Discriminator Loss: 0.5611857175827026, Generator Loss: 1.834080696105957\n",
      "Epoch: 192, Discriminator Loss: 0.6302538514137268, Generator Loss: 2.22556471824646\n",
      "Epoch: 193, Discriminator Loss: 0.3878443241119385, Generator Loss: 1.9097707271575928\n",
      "Epoch: 194, Discriminator Loss: 0.6688991785049438, Generator Loss: 2.08969783782959\n",
      "Epoch: 195, Discriminator Loss: 0.8047677278518677, Generator Loss: 1.7086267471313477\n",
      "Epoch: 196, Discriminator Loss: 0.6656973361968994, Generator Loss: 1.489957571029663\n",
      "Epoch: 197, Discriminator Loss: 0.657009482383728, Generator Loss: 1.698304533958435\n",
      "Epoch: 198, Discriminator Loss: 0.6402689814567566, Generator Loss: 1.7785303592681885\n",
      "Epoch: 199, Discriminator Loss: 0.7596551179885864, Generator Loss: 1.9728975296020508\n",
      "Epoch: 200, Discriminator Loss: 1.25877046585083, Generator Loss: 1.1560693979263306\n",
      "Epoch: 201, Discriminator Loss: 0.5998293161392212, Generator Loss: 1.566455364227295\n",
      "Epoch: 202, Discriminator Loss: 0.8785253763198853, Generator Loss: 1.2264020442962646\n",
      "Epoch: 203, Discriminator Loss: 0.5929761528968811, Generator Loss: 1.3683568239212036\n",
      "Epoch: 204, Discriminator Loss: 1.269595742225647, Generator Loss: 1.164323329925537\n",
      "Epoch: 205, Discriminator Loss: 0.6513427495956421, Generator Loss: 1.4059948921203613\n",
      "Epoch: 206, Discriminator Loss: 0.6338481903076172, Generator Loss: 1.5144977569580078\n",
      "Epoch: 207, Discriminator Loss: 0.748166561126709, Generator Loss: 1.4448013305664062\n",
      "Epoch: 208, Discriminator Loss: 1.0721994638442993, Generator Loss: 1.1175432205200195\n",
      "Epoch: 209, Discriminator Loss: 0.774345874786377, Generator Loss: 1.2462769746780396\n",
      "Epoch: 210, Discriminator Loss: 0.7427043914794922, Generator Loss: 1.0454742908477783\n",
      "Epoch: 211, Discriminator Loss: 0.8491264581680298, Generator Loss: 1.1214841604232788\n",
      "Epoch: 212, Discriminator Loss: 1.0223588943481445, Generator Loss: 1.1619417667388916\n",
      "Epoch: 213, Discriminator Loss: 1.0262997150421143, Generator Loss: 1.244206190109253\n",
      "Epoch: 214, Discriminator Loss: 0.8769185543060303, Generator Loss: 1.1384601593017578\n",
      "Epoch: 215, Discriminator Loss: 1.0115350484848022, Generator Loss: 1.2391057014465332\n",
      "Epoch: 216, Discriminator Loss: 0.8282157182693481, Generator Loss: 1.193966031074524\n",
      "Epoch: 217, Discriminator Loss: 0.749908983707428, Generator Loss: 1.3068490028381348\n",
      "Epoch: 218, Discriminator Loss: 1.1378226280212402, Generator Loss: 1.067420482635498\n",
      "Epoch: 219, Discriminator Loss: 0.9316175580024719, Generator Loss: 1.172636866569519\n",
      "Epoch: 220, Discriminator Loss: 0.9587428569793701, Generator Loss: 1.0755091905593872\n",
      "Epoch: 221, Discriminator Loss: 1.702232837677002, Generator Loss: 1.0367377996444702\n",
      "Epoch: 222, Discriminator Loss: 0.6807848215103149, Generator Loss: 1.1686575412750244\n",
      "Epoch: 223, Discriminator Loss: 1.0086658000946045, Generator Loss: 1.6060459613800049\n",
      "Epoch: 224, Discriminator Loss: 1.2243040800094604, Generator Loss: 1.270237922668457\n",
      "Epoch: 225, Discriminator Loss: 0.9210637211799622, Generator Loss: 1.4650758504867554\n",
      "Epoch: 226, Discriminator Loss: 1.3344714641571045, Generator Loss: 1.3830320835113525\n",
      "Epoch: 227, Discriminator Loss: 0.7435301542282104, Generator Loss: 1.7547568082809448\n",
      "Epoch: 228, Discriminator Loss: 0.985146164894104, Generator Loss: 1.699057936668396\n",
      "Epoch: 229, Discriminator Loss: 0.8083584904670715, Generator Loss: 1.3665533065795898\n",
      "Epoch: 230, Discriminator Loss: 1.1294636726379395, Generator Loss: 1.3196055889129639\n",
      "Epoch: 231, Discriminator Loss: 1.35395085811615, Generator Loss: 1.6598135232925415\n",
      "Epoch: 232, Discriminator Loss: 0.8509730100631714, Generator Loss: 1.8863033056259155\n",
      "Epoch: 233, Discriminator Loss: 0.9650483131408691, Generator Loss: 1.7178473472595215\n",
      "Epoch: 234, Discriminator Loss: 0.8105721473693848, Generator Loss: 1.8467150926589966\n",
      "Epoch: 235, Discriminator Loss: 0.7038160562515259, Generator Loss: 1.8505394458770752\n",
      "Epoch: 236, Discriminator Loss: 0.770319402217865, Generator Loss: 1.8498395681381226\n",
      "Epoch: 237, Discriminator Loss: 0.9828348159790039, Generator Loss: 1.681096076965332\n",
      "Epoch: 238, Discriminator Loss: 0.4894881248474121, Generator Loss: 1.4960565567016602\n",
      "Epoch: 239, Discriminator Loss: 0.7215429544448853, Generator Loss: 1.961470365524292\n",
      "Epoch: 240, Discriminator Loss: 0.4282023310661316, Generator Loss: 1.545873999595642\n",
      "Epoch: 241, Discriminator Loss: 0.959875226020813, Generator Loss: 1.895909070968628\n",
      "Epoch: 242, Discriminator Loss: 0.7943787574768066, Generator Loss: 1.8527097702026367\n",
      "Epoch: 243, Discriminator Loss: 0.4414573609828949, Generator Loss: 1.8923673629760742\n",
      "Epoch: 244, Discriminator Loss: 0.6333177089691162, Generator Loss: 1.9938406944274902\n",
      "Epoch: 245, Discriminator Loss: 0.5364102125167847, Generator Loss: 1.4229133129119873\n",
      "Epoch: 246, Discriminator Loss: 0.5043110847473145, Generator Loss: 2.112009048461914\n",
      "Epoch: 247, Discriminator Loss: 0.6416730880737305, Generator Loss: 1.684220314025879\n",
      "Epoch: 248, Discriminator Loss: 0.37271469831466675, Generator Loss: 2.0105652809143066\n",
      "Epoch: 249, Discriminator Loss: 0.5072846412658691, Generator Loss: 1.8262152671813965\n",
      "Epoch: 250, Discriminator Loss: 0.32295113801956177, Generator Loss: 2.045187473297119\n",
      "Epoch: 251, Discriminator Loss: 0.3532451391220093, Generator Loss: 2.0089166164398193\n",
      "Epoch: 252, Discriminator Loss: 0.7895638942718506, Generator Loss: 2.012024402618408\n",
      "Epoch: 253, Discriminator Loss: 0.5985309481620789, Generator Loss: 1.9074327945709229\n",
      "Epoch: 254, Discriminator Loss: 0.6573947668075562, Generator Loss: 2.033203601837158\n",
      "Epoch: 255, Discriminator Loss: 0.41422390937805176, Generator Loss: 1.763150930404663\n",
      "Epoch: 256, Discriminator Loss: 0.5750420093536377, Generator Loss: 2.0875649452209473\n",
      "Epoch: 257, Discriminator Loss: 0.6391794085502625, Generator Loss: 1.5142168998718262\n",
      "Epoch: 258, Discriminator Loss: 0.6225111484527588, Generator Loss: 1.5834171772003174\n",
      "Epoch: 259, Discriminator Loss: 0.6447204351425171, Generator Loss: 1.483797311782837\n",
      "Epoch: 260, Discriminator Loss: 0.40010571479797363, Generator Loss: 2.0132265090942383\n",
      "Epoch: 261, Discriminator Loss: 0.6402321457862854, Generator Loss: 1.5535826683044434\n",
      "Epoch: 262, Discriminator Loss: 0.6667473316192627, Generator Loss: 1.4247708320617676\n",
      "Epoch: 263, Discriminator Loss: 0.4751838445663452, Generator Loss: 1.59432852268219\n",
      "Epoch: 264, Discriminator Loss: 0.8786987066268921, Generator Loss: 1.3130614757537842\n",
      "Epoch: 265, Discriminator Loss: 0.7294440865516663, Generator Loss: 1.6639578342437744\n",
      "Epoch: 266, Discriminator Loss: 0.5817622542381287, Generator Loss: 1.367093563079834\n",
      "Epoch: 267, Discriminator Loss: 0.8627994060516357, Generator Loss: 1.3906714916229248\n",
      "Epoch: 268, Discriminator Loss: 0.8664064407348633, Generator Loss: 1.2433557510375977\n",
      "Epoch: 269, Discriminator Loss: 0.552626371383667, Generator Loss: 1.3430185317993164\n",
      "Epoch: 270, Discriminator Loss: 0.9255715608596802, Generator Loss: 1.4433062076568604\n",
      "Epoch: 271, Discriminator Loss: 0.9681177735328674, Generator Loss: 1.393567442893982\n",
      "Epoch: 272, Discriminator Loss: 1.0554225444793701, Generator Loss: 1.2371879816055298\n",
      "Epoch: 273, Discriminator Loss: 0.8177181482315063, Generator Loss: 1.1595590114593506\n",
      "Epoch: 274, Discriminator Loss: 0.8529160022735596, Generator Loss: 1.5126643180847168\n",
      "Epoch: 275, Discriminator Loss: 0.7420201897621155, Generator Loss: 1.2680201530456543\n",
      "Epoch: 276, Discriminator Loss: 0.6599686741828918, Generator Loss: 1.40000319480896\n",
      "Epoch: 277, Discriminator Loss: 0.7215021848678589, Generator Loss: 1.5974478721618652\n",
      "Epoch: 278, Discriminator Loss: 0.8376487493515015, Generator Loss: 1.126842975616455\n",
      "Epoch: 279, Discriminator Loss: 0.8779358863830566, Generator Loss: 1.2911380529403687\n",
      "Epoch: 280, Discriminator Loss: 0.7348587512969971, Generator Loss: 1.4892919063568115\n",
      "Epoch: 281, Discriminator Loss: 0.5887513160705566, Generator Loss: 1.478865146636963\n",
      "Epoch: 282, Discriminator Loss: 0.7115418910980225, Generator Loss: 1.5434303283691406\n",
      "Epoch: 283, Discriminator Loss: 0.7133148908615112, Generator Loss: 1.5656394958496094\n",
      "Epoch: 284, Discriminator Loss: 0.4835786819458008, Generator Loss: 1.438253402709961\n",
      "Epoch: 285, Discriminator Loss: 0.6481353044509888, Generator Loss: 1.9377968311309814\n",
      "Epoch: 286, Discriminator Loss: 1.2599033117294312, Generator Loss: 1.6036704778671265\n",
      "Epoch: 287, Discriminator Loss: 0.7587160468101501, Generator Loss: 1.7277805805206299\n",
      "Epoch: 288, Discriminator Loss: 0.8753842711448669, Generator Loss: 1.4920179843902588\n",
      "Epoch: 289, Discriminator Loss: 0.708085298538208, Generator Loss: 1.4809033870697021\n",
      "Epoch: 290, Discriminator Loss: 0.673629879951477, Generator Loss: 1.863046646118164\n",
      "Epoch: 291, Discriminator Loss: 1.0006815195083618, Generator Loss: 1.5832288265228271\n",
      "Epoch: 292, Discriminator Loss: 0.5676350593566895, Generator Loss: 2.003673553466797\n",
      "Epoch: 293, Discriminator Loss: 0.7830214500427246, Generator Loss: 1.5548720359802246\n",
      "Epoch: 294, Discriminator Loss: 0.474215567111969, Generator Loss: 1.7333898544311523\n",
      "Epoch: 295, Discriminator Loss: 1.0274176597595215, Generator Loss: 1.7203185558319092\n",
      "Epoch: 296, Discriminator Loss: 0.72127366065979, Generator Loss: 1.5135807991027832\n",
      "Epoch: 297, Discriminator Loss: 1.147667646408081, Generator Loss: 1.5830928087234497\n",
      "Epoch: 298, Discriminator Loss: 0.46780678629875183, Generator Loss: 2.0409631729125977\n",
      "Epoch: 299, Discriminator Loss: 0.6545507907867432, Generator Loss: 1.900289535522461\n",
      "Epoch: 300, Discriminator Loss: 0.6597405672073364, Generator Loss: 1.4553042650222778\n",
      "Epoch: 301, Discriminator Loss: 0.9564495086669922, Generator Loss: 1.9084982872009277\n",
      "Epoch: 302, Discriminator Loss: 0.5594756007194519, Generator Loss: 2.0656073093414307\n",
      "Epoch: 303, Discriminator Loss: 0.664670467376709, Generator Loss: 1.7842369079589844\n",
      "Epoch: 304, Discriminator Loss: 0.7576083540916443, Generator Loss: 2.1759033203125\n",
      "Epoch: 305, Discriminator Loss: 0.7758129835128784, Generator Loss: 1.7876592874526978\n",
      "Epoch: 306, Discriminator Loss: 0.5720687508583069, Generator Loss: 1.77294921875\n",
      "Epoch: 307, Discriminator Loss: 0.2913563847541809, Generator Loss: 2.095080852508545\n",
      "Epoch: 308, Discriminator Loss: 0.5360996723175049, Generator Loss: 1.7034178972244263\n",
      "Epoch: 309, Discriminator Loss: 0.384817898273468, Generator Loss: 2.3308112621307373\n",
      "Epoch: 310, Discriminator Loss: 0.6368408203125, Generator Loss: 2.0007894039154053\n",
      "Epoch: 311, Discriminator Loss: 0.6129084825515747, Generator Loss: 2.4842708110809326\n",
      "Epoch: 312, Discriminator Loss: 0.6442140340805054, Generator Loss: 1.7482256889343262\n",
      "Epoch: 313, Discriminator Loss: 0.4415817856788635, Generator Loss: 1.9870660305023193\n",
      "Epoch: 314, Discriminator Loss: 0.8302843570709229, Generator Loss: 2.078350067138672\n",
      "Epoch: 315, Discriminator Loss: 0.5524883270263672, Generator Loss: 1.7286052703857422\n",
      "Epoch: 316, Discriminator Loss: 0.5613052845001221, Generator Loss: 2.0614686012268066\n",
      "Epoch: 317, Discriminator Loss: 0.520489513874054, Generator Loss: 2.057668447494507\n",
      "Epoch: 318, Discriminator Loss: 0.5195607542991638, Generator Loss: 2.0882694721221924\n",
      "Epoch: 319, Discriminator Loss: 0.48571255803108215, Generator Loss: 2.029334545135498\n",
      "Epoch: 320, Discriminator Loss: 0.546598494052887, Generator Loss: 1.7763630151748657\n",
      "Epoch: 321, Discriminator Loss: 0.4255370795726776, Generator Loss: 1.9806721210479736\n",
      "Epoch: 322, Discriminator Loss: 0.677523672580719, Generator Loss: 1.8476710319519043\n",
      "Epoch: 323, Discriminator Loss: 0.5510386228561401, Generator Loss: 2.1986401081085205\n",
      "Epoch: 324, Discriminator Loss: 0.4631163477897644, Generator Loss: 2.0892434120178223\n",
      "Epoch: 325, Discriminator Loss: 0.6259815692901611, Generator Loss: 2.1384472846984863\n",
      "Epoch: 326, Discriminator Loss: 0.707735002040863, Generator Loss: 1.8268301486968994\n",
      "Epoch: 327, Discriminator Loss: 0.6089017987251282, Generator Loss: 1.4494454860687256\n",
      "Epoch: 328, Discriminator Loss: 0.459387868642807, Generator Loss: 1.7667917013168335\n",
      "Epoch: 329, Discriminator Loss: 0.709399938583374, Generator Loss: 1.6491870880126953\n",
      "Epoch: 330, Discriminator Loss: 0.7501068115234375, Generator Loss: 1.9785051345825195\n",
      "Epoch: 331, Discriminator Loss: 0.6847578287124634, Generator Loss: 1.5892096757888794\n",
      "Epoch: 332, Discriminator Loss: 0.41041290760040283, Generator Loss: 1.477142095565796\n",
      "Epoch: 333, Discriminator Loss: 0.7096126675605774, Generator Loss: 2.0669097900390625\n",
      "Epoch: 334, Discriminator Loss: 0.5435312986373901, Generator Loss: 2.083902359008789\n",
      "Epoch: 335, Discriminator Loss: 0.700499415397644, Generator Loss: 1.743582010269165\n",
      "Epoch: 336, Discriminator Loss: 0.4358544945716858, Generator Loss: 1.9208261966705322\n",
      "Epoch: 337, Discriminator Loss: 0.33819201588630676, Generator Loss: 2.182741165161133\n",
      "Epoch: 338, Discriminator Loss: 0.4458049535751343, Generator Loss: 1.7896523475646973\n",
      "Epoch: 339, Discriminator Loss: 0.6321927309036255, Generator Loss: 2.0346579551696777\n",
      "Epoch: 340, Discriminator Loss: 0.980803370475769, Generator Loss: 1.665694236755371\n",
      "Epoch: 341, Discriminator Loss: 0.5425748825073242, Generator Loss: 1.924045443534851\n",
      "Epoch: 342, Discriminator Loss: 0.44906651973724365, Generator Loss: 1.8541722297668457\n",
      "Epoch: 343, Discriminator Loss: 0.4825739860534668, Generator Loss: 1.6361675262451172\n",
      "Epoch: 344, Discriminator Loss: 0.6503580808639526, Generator Loss: 1.7113319635391235\n",
      "Epoch: 345, Discriminator Loss: 0.4790341854095459, Generator Loss: 1.4231162071228027\n",
      "Epoch: 346, Discriminator Loss: 0.7913416028022766, Generator Loss: 1.9900784492492676\n",
      "Epoch: 347, Discriminator Loss: 0.35607147216796875, Generator Loss: 2.285881519317627\n",
      "Epoch: 348, Discriminator Loss: 0.677149772644043, Generator Loss: 1.530815839767456\n",
      "Epoch: 349, Discriminator Loss: 0.9928567409515381, Generator Loss: 1.4715242385864258\n",
      "Epoch: 350, Discriminator Loss: 0.8338809013366699, Generator Loss: 1.7599287033081055\n",
      "Epoch: 351, Discriminator Loss: 0.47187721729278564, Generator Loss: 1.816967487335205\n",
      "Epoch: 352, Discriminator Loss: 0.7941094636917114, Generator Loss: 1.7391103506088257\n",
      "Epoch: 353, Discriminator Loss: 0.6480130553245544, Generator Loss: 1.5869100093841553\n",
      "Epoch: 354, Discriminator Loss: 0.5200240612030029, Generator Loss: 1.6932897567749023\n",
      "Epoch: 355, Discriminator Loss: 0.6704344749450684, Generator Loss: 1.7093353271484375\n",
      "Epoch: 356, Discriminator Loss: 0.6057568192481995, Generator Loss: 1.4537510871887207\n",
      "Epoch: 357, Discriminator Loss: 0.8689032196998596, Generator Loss: 1.8702709674835205\n",
      "Epoch: 358, Discriminator Loss: 0.6753840446472168, Generator Loss: 2.060417890548706\n",
      "Epoch: 359, Discriminator Loss: 0.9514575004577637, Generator Loss: 1.8491356372833252\n",
      "Epoch: 360, Discriminator Loss: 0.5580849647521973, Generator Loss: 2.39632511138916\n",
      "Epoch: 361, Discriminator Loss: 0.45689383149147034, Generator Loss: 2.0079615116119385\n",
      "Epoch: 362, Discriminator Loss: 0.520572304725647, Generator Loss: 1.8854323625564575\n",
      "Epoch: 363, Discriminator Loss: 0.5512214303016663, Generator Loss: 1.6882526874542236\n",
      "Epoch: 364, Discriminator Loss: 0.749703049659729, Generator Loss: 1.9060957431793213\n",
      "Epoch: 365, Discriminator Loss: 0.5886543989181519, Generator Loss: 1.8683180809020996\n",
      "Epoch: 366, Discriminator Loss: 0.8103914260864258, Generator Loss: 2.0075507164001465\n",
      "Epoch: 367, Discriminator Loss: 0.3953520953655243, Generator Loss: 1.8396425247192383\n",
      "Epoch: 368, Discriminator Loss: 0.6398462057113647, Generator Loss: 1.7239654064178467\n",
      "Epoch: 369, Discriminator Loss: 0.4331384301185608, Generator Loss: 1.4516241550445557\n",
      "Epoch: 370, Discriminator Loss: 0.643354594707489, Generator Loss: 1.9133821725845337\n",
      "Epoch: 371, Discriminator Loss: 0.46742427349090576, Generator Loss: 1.9591801166534424\n",
      "Epoch: 372, Discriminator Loss: 0.4414686858654022, Generator Loss: 2.013256549835205\n",
      "Epoch: 373, Discriminator Loss: 0.41741377115249634, Generator Loss: 1.8107848167419434\n",
      "Epoch: 374, Discriminator Loss: 0.6446257829666138, Generator Loss: 1.9340342283248901\n",
      "Epoch: 375, Discriminator Loss: 1.0086443424224854, Generator Loss: 1.959648609161377\n",
      "Epoch: 376, Discriminator Loss: 0.4479798674583435, Generator Loss: 1.7158100605010986\n",
      "Epoch: 377, Discriminator Loss: 0.7650131583213806, Generator Loss: 1.7744896411895752\n",
      "Epoch: 378, Discriminator Loss: 0.9642743468284607, Generator Loss: 1.95381498336792\n",
      "Epoch: 379, Discriminator Loss: 0.9892258644104004, Generator Loss: 1.6989104747772217\n",
      "Epoch: 380, Discriminator Loss: 0.777768611907959, Generator Loss: 1.7333258390426636\n",
      "Epoch: 381, Discriminator Loss: 0.808850884437561, Generator Loss: 1.5252217054367065\n",
      "Epoch: 382, Discriminator Loss: 0.7935867309570312, Generator Loss: 1.533715009689331\n",
      "Epoch: 383, Discriminator Loss: 0.6934944987297058, Generator Loss: 1.7618070840835571\n",
      "Epoch: 384, Discriminator Loss: 0.9581689834594727, Generator Loss: 1.7978118658065796\n",
      "Epoch: 385, Discriminator Loss: 0.6474629640579224, Generator Loss: 1.824340581893921\n",
      "Epoch: 386, Discriminator Loss: 0.7367521524429321, Generator Loss: 1.4535397291183472\n",
      "Epoch: 387, Discriminator Loss: 1.1813740730285645, Generator Loss: 1.5191718339920044\n",
      "Epoch: 388, Discriminator Loss: 0.5826042890548706, Generator Loss: 1.3445018529891968\n",
      "Epoch: 389, Discriminator Loss: 0.8118836283683777, Generator Loss: 2.203777313232422\n",
      "Epoch: 390, Discriminator Loss: 0.7840456962585449, Generator Loss: 1.6117446422576904\n",
      "Epoch: 391, Discriminator Loss: 0.5829784870147705, Generator Loss: 1.316107153892517\n",
      "Epoch: 392, Discriminator Loss: 0.6151771545410156, Generator Loss: 1.441874384880066\n",
      "Epoch: 393, Discriminator Loss: 0.8159180879592896, Generator Loss: 1.8001999855041504\n",
      "Epoch: 394, Discriminator Loss: 0.7014504671096802, Generator Loss: 1.7910404205322266\n",
      "Epoch: 395, Discriminator Loss: 0.8733500242233276, Generator Loss: 1.711991548538208\n",
      "Epoch: 396, Discriminator Loss: 0.5765478014945984, Generator Loss: 1.7221488952636719\n",
      "Epoch: 397, Discriminator Loss: 0.4919336438179016, Generator Loss: 1.7412534952163696\n",
      "Epoch: 398, Discriminator Loss: 0.33531519770622253, Generator Loss: 1.7210562229156494\n",
      "Epoch: 399, Discriminator Loss: 0.6756227016448975, Generator Loss: 1.7118477821350098\n",
      "Epoch: 400, Discriminator Loss: 0.7907918691635132, Generator Loss: 1.7750859260559082\n",
      "Epoch: 401, Discriminator Loss: 0.5719588398933411, Generator Loss: 1.626107931137085\n",
      "Epoch: 402, Discriminator Loss: 0.48913878202438354, Generator Loss: 2.2128143310546875\n",
      "Epoch: 403, Discriminator Loss: 0.5912736058235168, Generator Loss: 1.7391042709350586\n",
      "Epoch: 404, Discriminator Loss: 0.47409147024154663, Generator Loss: 1.9947391748428345\n",
      "Epoch: 405, Discriminator Loss: 0.5087587833404541, Generator Loss: 1.8650048971176147\n",
      "Epoch: 406, Discriminator Loss: 0.6986575126647949, Generator Loss: 1.8258461952209473\n",
      "Epoch: 407, Discriminator Loss: 0.5917071104049683, Generator Loss: 1.5697331428527832\n",
      "Epoch: 408, Discriminator Loss: 0.5946394801139832, Generator Loss: 1.7787507772445679\n",
      "Epoch: 409, Discriminator Loss: 0.9212524890899658, Generator Loss: 2.0086328983306885\n",
      "Epoch: 410, Discriminator Loss: 0.650097668170929, Generator Loss: 1.4745327234268188\n",
      "Epoch: 411, Discriminator Loss: 0.8801379203796387, Generator Loss: 1.5385465621948242\n",
      "Epoch: 412, Discriminator Loss: 0.5149251818656921, Generator Loss: 2.078599691390991\n",
      "Epoch: 413, Discriminator Loss: 0.6593058109283447, Generator Loss: 1.4711999893188477\n",
      "Epoch: 414, Discriminator Loss: 0.7196561694145203, Generator Loss: 1.706756353378296\n",
      "Epoch: 415, Discriminator Loss: 0.7170960903167725, Generator Loss: 1.9638127088546753\n",
      "Epoch: 416, Discriminator Loss: 0.3991762399673462, Generator Loss: 1.9323731660842896\n",
      "Epoch: 417, Discriminator Loss: 0.8863279223442078, Generator Loss: 1.7081325054168701\n",
      "Epoch: 418, Discriminator Loss: 0.7376593351364136, Generator Loss: 2.007859230041504\n",
      "Epoch: 419, Discriminator Loss: 0.5738908052444458, Generator Loss: 2.023972511291504\n",
      "Epoch: 420, Discriminator Loss: 0.4336816072463989, Generator Loss: 1.8780391216278076\n",
      "Epoch: 421, Discriminator Loss: 0.6034110188484192, Generator Loss: 1.9482595920562744\n",
      "Epoch: 422, Discriminator Loss: 0.6218750476837158, Generator Loss: 1.6441519260406494\n",
      "Epoch: 423, Discriminator Loss: 0.6225937604904175, Generator Loss: 1.7453293800354004\n",
      "Epoch: 424, Discriminator Loss: 0.6617808938026428, Generator Loss: 1.8238863945007324\n",
      "Epoch: 425, Discriminator Loss: 0.38461464643478394, Generator Loss: 1.9248695373535156\n",
      "Epoch: 426, Discriminator Loss: 0.6606227159500122, Generator Loss: 1.542231798171997\n",
      "Epoch: 427, Discriminator Loss: 0.8540277481079102, Generator Loss: 1.8255561590194702\n",
      "Epoch: 428, Discriminator Loss: 0.5805196762084961, Generator Loss: 1.5918952226638794\n",
      "Epoch: 429, Discriminator Loss: 0.5108832120895386, Generator Loss: 1.6343300342559814\n",
      "Epoch: 430, Discriminator Loss: 0.5625013113021851, Generator Loss: 1.8489068746566772\n",
      "Epoch: 431, Discriminator Loss: 0.38775503635406494, Generator Loss: 1.8889849185943604\n",
      "Epoch: 432, Discriminator Loss: 0.48156535625457764, Generator Loss: 2.0022950172424316\n",
      "Epoch: 433, Discriminator Loss: 0.3986224830150604, Generator Loss: 2.3798301219940186\n",
      "Epoch: 434, Discriminator Loss: 0.662307858467102, Generator Loss: 2.313730239868164\n",
      "Epoch: 435, Discriminator Loss: 0.5700668096542358, Generator Loss: 1.9094370603561401\n",
      "Epoch: 436, Discriminator Loss: 0.6174039244651794, Generator Loss: 1.823566198348999\n",
      "Epoch: 437, Discriminator Loss: 0.6790745258331299, Generator Loss: 2.0701546669006348\n",
      "Epoch: 438, Discriminator Loss: 0.582104504108429, Generator Loss: 1.977250099182129\n",
      "Epoch: 439, Discriminator Loss: 0.3774756193161011, Generator Loss: 1.9014500379562378\n",
      "Epoch: 440, Discriminator Loss: 0.5542259216308594, Generator Loss: 1.99506676197052\n",
      "Epoch: 441, Discriminator Loss: 0.4658886194229126, Generator Loss: 1.5950820446014404\n",
      "Epoch: 442, Discriminator Loss: 0.3616596460342407, Generator Loss: 2.5280861854553223\n",
      "Epoch: 443, Discriminator Loss: 0.5666146278381348, Generator Loss: 1.8180005550384521\n",
      "Epoch: 444, Discriminator Loss: 0.7988642454147339, Generator Loss: 2.13687801361084\n",
      "Epoch: 445, Discriminator Loss: 0.7779884338378906, Generator Loss: 2.1654436588287354\n",
      "Epoch: 446, Discriminator Loss: 0.7202630639076233, Generator Loss: 2.336132526397705\n",
      "Epoch: 447, Discriminator Loss: 0.4233730435371399, Generator Loss: 2.2466304302215576\n",
      "Epoch: 448, Discriminator Loss: 0.4162006080150604, Generator Loss: 2.2584710121154785\n",
      "Epoch: 449, Discriminator Loss: 0.7380994558334351, Generator Loss: 2.37821626663208\n",
      "Epoch: 450, Discriminator Loss: 0.5313546657562256, Generator Loss: 1.8986161947250366\n",
      "Epoch: 451, Discriminator Loss: 0.7586559653282166, Generator Loss: 1.8029823303222656\n",
      "Epoch: 452, Discriminator Loss: 0.46855199337005615, Generator Loss: 2.118161916732788\n",
      "Epoch: 453, Discriminator Loss: 0.5131366848945618, Generator Loss: 1.8215996026992798\n",
      "Epoch: 454, Discriminator Loss: 0.49141865968704224, Generator Loss: 1.6903373003005981\n",
      "Epoch: 455, Discriminator Loss: 0.4570414423942566, Generator Loss: 1.8066895008087158\n",
      "Epoch: 456, Discriminator Loss: 0.4846077263355255, Generator Loss: 2.1211392879486084\n",
      "Epoch: 457, Discriminator Loss: 0.4911954700946808, Generator Loss: 1.783449411392212\n",
      "Epoch: 458, Discriminator Loss: 0.6522153615951538, Generator Loss: 1.7593246698379517\n",
      "Epoch: 459, Discriminator Loss: 0.4589594900608063, Generator Loss: 1.8040847778320312\n",
      "Epoch: 460, Discriminator Loss: 0.4693632125854492, Generator Loss: 2.103720188140869\n",
      "Epoch: 461, Discriminator Loss: 0.34796595573425293, Generator Loss: 2.4822888374328613\n",
      "Epoch: 462, Discriminator Loss: 0.5764096975326538, Generator Loss: 1.9144799709320068\n",
      "Epoch: 463, Discriminator Loss: 0.527538537979126, Generator Loss: 2.0105154514312744\n",
      "Epoch: 464, Discriminator Loss: 0.5122929811477661, Generator Loss: 1.7428746223449707\n",
      "Epoch: 465, Discriminator Loss: 0.29390010237693787, Generator Loss: 2.5190186500549316\n",
      "Epoch: 466, Discriminator Loss: 0.5724078416824341, Generator Loss: 2.1235578060150146\n",
      "Epoch: 467, Discriminator Loss: 0.4718014597892761, Generator Loss: 2.039706230163574\n",
      "Epoch: 468, Discriminator Loss: 0.3963133692741394, Generator Loss: 2.2334446907043457\n",
      "Epoch: 469, Discriminator Loss: 0.6698229312896729, Generator Loss: 1.903554081916809\n",
      "Epoch: 470, Discriminator Loss: 0.7862714529037476, Generator Loss: 1.8016092777252197\n",
      "Epoch: 471, Discriminator Loss: 0.3195759356021881, Generator Loss: 2.0034542083740234\n",
      "Epoch: 472, Discriminator Loss: 0.5488905906677246, Generator Loss: 2.3373100757598877\n",
      "Epoch: 473, Discriminator Loss: 0.47969627380371094, Generator Loss: 1.9179966449737549\n",
      "Epoch: 474, Discriminator Loss: 0.7933056354522705, Generator Loss: 2.2223236560821533\n",
      "Epoch: 475, Discriminator Loss: 0.5302988290786743, Generator Loss: 2.3658502101898193\n",
      "Epoch: 476, Discriminator Loss: 0.6640021800994873, Generator Loss: 1.9579640626907349\n",
      "Epoch: 477, Discriminator Loss: 0.45496952533721924, Generator Loss: 2.2984776496887207\n",
      "Epoch: 478, Discriminator Loss: 0.45984187722206116, Generator Loss: 2.230130434036255\n",
      "Epoch: 479, Discriminator Loss: 0.36381760239601135, Generator Loss: 1.9484460353851318\n",
      "Epoch: 480, Discriminator Loss: 0.48357513546943665, Generator Loss: 1.651963233947754\n",
      "Epoch: 481, Discriminator Loss: 0.3563072979450226, Generator Loss: 2.619513511657715\n",
      "Epoch: 482, Discriminator Loss: 0.5967482924461365, Generator Loss: 1.531518578529358\n",
      "Epoch: 483, Discriminator Loss: 0.520912766456604, Generator Loss: 1.7962753772735596\n",
      "Epoch: 484, Discriminator Loss: 0.47387540340423584, Generator Loss: 1.9131516218185425\n",
      "Epoch: 485, Discriminator Loss: 0.3672124445438385, Generator Loss: 1.8961031436920166\n",
      "Epoch: 486, Discriminator Loss: 0.6642694473266602, Generator Loss: 1.7243549823760986\n",
      "Epoch: 487, Discriminator Loss: 0.7013994455337524, Generator Loss: 1.9957549571990967\n",
      "Epoch: 488, Discriminator Loss: 0.7563762068748474, Generator Loss: 1.8903546333312988\n",
      "Epoch: 489, Discriminator Loss: 0.7506633996963501, Generator Loss: 1.7798089981079102\n",
      "Epoch: 490, Discriminator Loss: 0.7135235667228699, Generator Loss: 1.6629948616027832\n",
      "Epoch: 491, Discriminator Loss: 0.410567045211792, Generator Loss: 1.993906855583191\n",
      "Epoch: 492, Discriminator Loss: 0.5179812908172607, Generator Loss: 2.0585122108459473\n",
      "Epoch: 493, Discriminator Loss: 0.5158017873764038, Generator Loss: 2.366711378097534\n",
      "Epoch: 494, Discriminator Loss: 0.4383293390274048, Generator Loss: 1.8905733823776245\n",
      "Epoch: 495, Discriminator Loss: 0.5388751029968262, Generator Loss: 1.9728150367736816\n",
      "Epoch: 496, Discriminator Loss: 0.8047473430633545, Generator Loss: 1.8069781064987183\n",
      "Epoch: 497, Discriminator Loss: 0.6802630424499512, Generator Loss: 1.8033413887023926\n",
      "Epoch: 498, Discriminator Loss: 0.4646427631378174, Generator Loss: 1.6180574893951416\n",
      "Epoch: 499, Discriminator Loss: 0.5193720459938049, Generator Loss: 1.6497151851654053\n",
      "Epoch: 500, Discriminator Loss: 0.9041293859481812, Generator Loss: 2.287799596786499\n",
      "Epoch: 501, Discriminator Loss: 0.41562145948410034, Generator Loss: 2.2437174320220947\n",
      "Epoch: 502, Discriminator Loss: 0.6488878726959229, Generator Loss: 1.5505261421203613\n",
      "Epoch: 503, Discriminator Loss: 0.6381440758705139, Generator Loss: 2.0954089164733887\n",
      "Epoch: 504, Discriminator Loss: 0.5770273208618164, Generator Loss: 2.189743757247925\n",
      "Epoch: 505, Discriminator Loss: 0.8102121949195862, Generator Loss: 1.888347864151001\n",
      "Epoch: 506, Discriminator Loss: 0.7126109600067139, Generator Loss: 2.181215286254883\n",
      "Epoch: 507, Discriminator Loss: 0.46813076734542847, Generator Loss: 1.825282335281372\n",
      "Epoch: 508, Discriminator Loss: 0.4645322263240814, Generator Loss: 2.123140811920166\n",
      "Epoch: 509, Discriminator Loss: 0.7433763742446899, Generator Loss: 1.5548312664031982\n",
      "Epoch: 510, Discriminator Loss: 0.4951574206352234, Generator Loss: 1.5863792896270752\n",
      "Epoch: 511, Discriminator Loss: 0.4001075029373169, Generator Loss: 1.9786150455474854\n",
      "Epoch: 512, Discriminator Loss: 0.6957053542137146, Generator Loss: 1.884900450706482\n",
      "Epoch: 513, Discriminator Loss: 0.8792232871055603, Generator Loss: 2.045776605606079\n",
      "Epoch: 514, Discriminator Loss: 0.7425949573516846, Generator Loss: 2.1544675827026367\n",
      "Epoch: 515, Discriminator Loss: 0.44319504499435425, Generator Loss: 1.5310356616973877\n",
      "Epoch: 516, Discriminator Loss: 0.823477029800415, Generator Loss: 2.0988454818725586\n",
      "Epoch: 517, Discriminator Loss: 0.6320313811302185, Generator Loss: 1.7284198999404907\n",
      "Epoch: 518, Discriminator Loss: 0.8144445419311523, Generator Loss: 1.996168851852417\n",
      "Epoch: 519, Discriminator Loss: 0.46320047974586487, Generator Loss: 2.2128546237945557\n",
      "Epoch: 520, Discriminator Loss: 0.7777695655822754, Generator Loss: 1.9006376266479492\n",
      "Epoch: 521, Discriminator Loss: 0.6569185853004456, Generator Loss: 1.8885470628738403\n",
      "Epoch: 522, Discriminator Loss: 0.38307029008865356, Generator Loss: 1.97495698928833\n",
      "Epoch: 523, Discriminator Loss: 0.4975247383117676, Generator Loss: 1.801848292350769\n",
      "Epoch: 524, Discriminator Loss: 0.727141261100769, Generator Loss: 1.6983476877212524\n",
      "Epoch: 525, Discriminator Loss: 0.431164026260376, Generator Loss: 1.8763948678970337\n",
      "Epoch: 526, Discriminator Loss: 0.44305434823036194, Generator Loss: 1.519674301147461\n",
      "Epoch: 527, Discriminator Loss: 0.549718976020813, Generator Loss: 2.1135361194610596\n",
      "Epoch: 528, Discriminator Loss: 0.723840594291687, Generator Loss: 1.7427619695663452\n",
      "Epoch: 529, Discriminator Loss: 0.5050114989280701, Generator Loss: 1.9883396625518799\n",
      "Epoch: 530, Discriminator Loss: 0.5928246974945068, Generator Loss: 1.752854585647583\n",
      "Epoch: 531, Discriminator Loss: 0.6227375268936157, Generator Loss: 2.056760787963867\n",
      "Epoch: 532, Discriminator Loss: 0.6036432385444641, Generator Loss: 1.6387053728103638\n",
      "Epoch: 533, Discriminator Loss: 0.587633490562439, Generator Loss: 2.3399534225463867\n",
      "Epoch: 534, Discriminator Loss: 0.42551863193511963, Generator Loss: 2.1038382053375244\n",
      "Epoch: 535, Discriminator Loss: 0.8661128878593445, Generator Loss: 2.2601075172424316\n",
      "Epoch: 536, Discriminator Loss: 0.4549599885940552, Generator Loss: 1.8715766668319702\n",
      "Epoch: 537, Discriminator Loss: 0.5771046876907349, Generator Loss: 2.112720489501953\n",
      "Epoch: 538, Discriminator Loss: 0.7087841629981995, Generator Loss: 2.2569451332092285\n",
      "Epoch: 539, Discriminator Loss: 0.4938827157020569, Generator Loss: 2.162832260131836\n",
      "Epoch: 540, Discriminator Loss: 0.5949181318283081, Generator Loss: 1.7455389499664307\n",
      "Epoch: 541, Discriminator Loss: 0.521175742149353, Generator Loss: 1.985769271850586\n",
      "Epoch: 542, Discriminator Loss: 0.5648874044418335, Generator Loss: 2.165933847427368\n",
      "Epoch: 543, Discriminator Loss: 0.5563027858734131, Generator Loss: 2.071023464202881\n",
      "Epoch: 544, Discriminator Loss: 0.5686919093132019, Generator Loss: 1.7065608501434326\n",
      "Epoch: 545, Discriminator Loss: 0.8256663680076599, Generator Loss: 2.3669514656066895\n",
      "Epoch: 546, Discriminator Loss: 0.5557670593261719, Generator Loss: 2.36474609375\n",
      "Epoch: 547, Discriminator Loss: 0.7060239315032959, Generator Loss: 2.0984249114990234\n",
      "Epoch: 548, Discriminator Loss: 0.46684765815734863, Generator Loss: 1.722566843032837\n",
      "Epoch: 549, Discriminator Loss: 0.9229368567466736, Generator Loss: 2.084101915359497\n",
      "Epoch: 550, Discriminator Loss: 0.9949018955230713, Generator Loss: 2.073460340499878\n",
      "Epoch: 551, Discriminator Loss: 0.6445973515510559, Generator Loss: 1.9499340057373047\n",
      "Epoch: 552, Discriminator Loss: 0.3626187741756439, Generator Loss: 1.9653301239013672\n",
      "Epoch: 553, Discriminator Loss: 0.34751492738723755, Generator Loss: 1.5990651845932007\n",
      "Epoch: 554, Discriminator Loss: 0.5118180513381958, Generator Loss: 1.8879483938217163\n",
      "Epoch: 555, Discriminator Loss: 0.8253543972969055, Generator Loss: 1.729724645614624\n",
      "Epoch: 556, Discriminator Loss: 0.5342211127281189, Generator Loss: 2.354564666748047\n",
      "Epoch: 557, Discriminator Loss: 0.3792039155960083, Generator Loss: 2.052384853363037\n",
      "Epoch: 558, Discriminator Loss: 0.2439558357000351, Generator Loss: 1.7618072032928467\n",
      "Epoch: 559, Discriminator Loss: 0.46807417273521423, Generator Loss: 1.9009318351745605\n",
      "Epoch: 560, Discriminator Loss: 0.4608950912952423, Generator Loss: 2.0241284370422363\n",
      "Epoch: 561, Discriminator Loss: 0.80842125415802, Generator Loss: 1.7877981662750244\n",
      "Epoch: 562, Discriminator Loss: 0.612908124923706, Generator Loss: 1.8911793231964111\n",
      "Epoch: 563, Discriminator Loss: 0.6953539252281189, Generator Loss: 2.018876552581787\n",
      "Epoch: 564, Discriminator Loss: 0.36736762523651123, Generator Loss: 1.9910297393798828\n",
      "Epoch: 565, Discriminator Loss: 0.7257567644119263, Generator Loss: 1.7768287658691406\n",
      "Epoch: 566, Discriminator Loss: 0.5357898473739624, Generator Loss: 1.4885201454162598\n",
      "Epoch: 567, Discriminator Loss: 0.3854728937149048, Generator Loss: 1.8606204986572266\n",
      "Epoch: 568, Discriminator Loss: 0.4252910017967224, Generator Loss: 2.1858742237091064\n",
      "Epoch: 569, Discriminator Loss: 0.5829316973686218, Generator Loss: 2.083462953567505\n",
      "Epoch: 570, Discriminator Loss: 0.6286731958389282, Generator Loss: 2.7921206951141357\n",
      "Epoch: 571, Discriminator Loss: 0.3657069504261017, Generator Loss: 2.241016149520874\n",
      "Epoch: 572, Discriminator Loss: 0.8907566666603088, Generator Loss: 1.913355827331543\n",
      "Epoch: 573, Discriminator Loss: 0.578519344329834, Generator Loss: 2.0251095294952393\n",
      "Epoch: 574, Discriminator Loss: 0.7401416301727295, Generator Loss: 2.049807548522949\n",
      "Epoch: 575, Discriminator Loss: 0.5288354754447937, Generator Loss: 1.7822628021240234\n",
      "Epoch: 576, Discriminator Loss: 0.575117826461792, Generator Loss: 2.098313808441162\n",
      "Epoch: 577, Discriminator Loss: 0.5709905624389648, Generator Loss: 1.9121510982513428\n",
      "Epoch: 578, Discriminator Loss: 0.6187208294868469, Generator Loss: 2.072523832321167\n",
      "Epoch: 579, Discriminator Loss: 0.6544522047042847, Generator Loss: 2.2476773262023926\n",
      "Epoch: 580, Discriminator Loss: 0.5421390533447266, Generator Loss: 2.0771188735961914\n",
      "Epoch: 581, Discriminator Loss: 0.3444664478302002, Generator Loss: 2.300555467605591\n",
      "Epoch: 582, Discriminator Loss: 0.3326265811920166, Generator Loss: 2.4053516387939453\n",
      "Epoch: 583, Discriminator Loss: 0.8517767190933228, Generator Loss: 2.0165812969207764\n",
      "Epoch: 584, Discriminator Loss: 0.5719033479690552, Generator Loss: 2.2583250999450684\n",
      "Epoch: 585, Discriminator Loss: 0.49743276834487915, Generator Loss: 2.257943630218506\n",
      "Epoch: 586, Discriminator Loss: 0.5483900308609009, Generator Loss: 2.022500991821289\n",
      "Epoch: 587, Discriminator Loss: 0.7968183755874634, Generator Loss: 2.0537309646606445\n",
      "Epoch: 588, Discriminator Loss: 0.6834644079208374, Generator Loss: 2.519052505493164\n",
      "Epoch: 589, Discriminator Loss: 0.5397711992263794, Generator Loss: 1.9396921396255493\n",
      "Epoch: 590, Discriminator Loss: 0.8749628663063049, Generator Loss: 2.2396059036254883\n",
      "Epoch: 591, Discriminator Loss: 0.5375267267227173, Generator Loss: 1.9936507940292358\n",
      "Epoch: 592, Discriminator Loss: 0.7635414600372314, Generator Loss: 2.1531944274902344\n",
      "Epoch: 593, Discriminator Loss: 0.8935648202896118, Generator Loss: 2.069859504699707\n",
      "Epoch: 594, Discriminator Loss: 0.3775886297225952, Generator Loss: 2.4118540287017822\n",
      "Epoch: 595, Discriminator Loss: 0.3656524121761322, Generator Loss: 2.1406362056732178\n",
      "Epoch: 596, Discriminator Loss: 0.35299932956695557, Generator Loss: 2.1815218925476074\n",
      "Epoch: 597, Discriminator Loss: 0.5591116547584534, Generator Loss: 1.9375814199447632\n",
      "Epoch: 598, Discriminator Loss: 0.46277254819869995, Generator Loss: 1.9269015789031982\n",
      "Epoch: 599, Discriminator Loss: 0.5966665148735046, Generator Loss: 1.9632209539413452\n",
      "Epoch: 600, Discriminator Loss: 0.34644263982772827, Generator Loss: 2.098710060119629\n",
      "Epoch: 601, Discriminator Loss: 0.4315541982650757, Generator Loss: 2.0548434257507324\n",
      "Epoch: 602, Discriminator Loss: 0.5335630774497986, Generator Loss: 2.3736324310302734\n",
      "Epoch: 603, Discriminator Loss: 0.8785950541496277, Generator Loss: 2.8813629150390625\n",
      "Epoch: 604, Discriminator Loss: 0.6435344815254211, Generator Loss: 1.7914823293685913\n",
      "Epoch: 605, Discriminator Loss: 0.8504726886749268, Generator Loss: 2.102724552154541\n",
      "Epoch: 606, Discriminator Loss: 0.6541160941123962, Generator Loss: 2.1713452339172363\n",
      "Epoch: 607, Discriminator Loss: 0.5612030029296875, Generator Loss: 2.367727041244507\n",
      "Epoch: 608, Discriminator Loss: 0.5342994332313538, Generator Loss: 2.4833173751831055\n",
      "Epoch: 609, Discriminator Loss: 0.2033368945121765, Generator Loss: 2.1552963256835938\n",
      "Epoch: 610, Discriminator Loss: 0.2507518231868744, Generator Loss: 1.840336799621582\n",
      "Epoch: 611, Discriminator Loss: 0.4668341279029846, Generator Loss: 1.7467236518859863\n",
      "Epoch: 612, Discriminator Loss: 0.7624384760856628, Generator Loss: 1.818068504333496\n",
      "Epoch: 613, Discriminator Loss: 0.6118966937065125, Generator Loss: 2.40844988822937\n",
      "Epoch: 614, Discriminator Loss: 0.3062390685081482, Generator Loss: 1.9428112506866455\n",
      "Epoch: 615, Discriminator Loss: 0.5136585235595703, Generator Loss: 1.7301702499389648\n",
      "Epoch: 616, Discriminator Loss: 0.3370513319969177, Generator Loss: 1.8660446405410767\n",
      "Epoch: 617, Discriminator Loss: 0.3848183751106262, Generator Loss: 2.1660842895507812\n",
      "Epoch: 618, Discriminator Loss: 0.5975703597068787, Generator Loss: 2.5629186630249023\n",
      "Epoch: 619, Discriminator Loss: 0.752342939376831, Generator Loss: 2.0247039794921875\n",
      "Epoch: 620, Discriminator Loss: 0.4715973436832428, Generator Loss: 2.176677703857422\n",
      "Epoch: 621, Discriminator Loss: 0.5165954828262329, Generator Loss: 2.016900062561035\n",
      "Epoch: 622, Discriminator Loss: 0.4360893964767456, Generator Loss: 2.523374080657959\n",
      "Epoch: 623, Discriminator Loss: 0.8036162853240967, Generator Loss: 2.32981538772583\n",
      "Epoch: 624, Discriminator Loss: 0.31486231088638306, Generator Loss: 2.2596495151519775\n",
      "Epoch: 625, Discriminator Loss: 0.371633380651474, Generator Loss: 2.322594165802002\n",
      "Epoch: 626, Discriminator Loss: 0.6940270066261292, Generator Loss: 2.490055799484253\n",
      "Epoch: 627, Discriminator Loss: 0.46854713559150696, Generator Loss: 2.6210145950317383\n",
      "Epoch: 628, Discriminator Loss: 0.5413244962692261, Generator Loss: 2.3390636444091797\n",
      "Epoch: 629, Discriminator Loss: 0.46481817960739136, Generator Loss: 2.085116147994995\n",
      "Epoch: 630, Discriminator Loss: 0.3271391689777374, Generator Loss: 2.0212807655334473\n",
      "Epoch: 631, Discriminator Loss: 0.5079190731048584, Generator Loss: 1.9260669946670532\n",
      "Epoch: 632, Discriminator Loss: 0.6436149477958679, Generator Loss: 1.5770385265350342\n",
      "Epoch: 633, Discriminator Loss: 0.3713458180427551, Generator Loss: 2.37137508392334\n",
      "Epoch: 634, Discriminator Loss: 0.4620961546897888, Generator Loss: 2.091425895690918\n",
      "Epoch: 635, Discriminator Loss: 0.33920520544052124, Generator Loss: 2.038166046142578\n",
      "Epoch: 636, Discriminator Loss: 0.519620418548584, Generator Loss: 2.3365397453308105\n",
      "Epoch: 637, Discriminator Loss: 0.5117044448852539, Generator Loss: 2.2983076572418213\n",
      "Epoch: 638, Discriminator Loss: 0.6036655902862549, Generator Loss: 1.8581409454345703\n",
      "Epoch: 639, Discriminator Loss: 0.6299797296524048, Generator Loss: 2.0151610374450684\n",
      "Epoch: 640, Discriminator Loss: 0.745505154132843, Generator Loss: 1.6003479957580566\n",
      "Epoch: 641, Discriminator Loss: 0.6091023683547974, Generator Loss: 1.9120217561721802\n",
      "Epoch: 642, Discriminator Loss: 0.48870235681533813, Generator Loss: 1.7284417152404785\n",
      "Epoch: 643, Discriminator Loss: 0.645606279373169, Generator Loss: 1.693781852722168\n",
      "Epoch: 644, Discriminator Loss: 0.3559298515319824, Generator Loss: 1.690996766090393\n",
      "Epoch: 645, Discriminator Loss: 0.7044144868850708, Generator Loss: 1.709669589996338\n",
      "Epoch: 646, Discriminator Loss: 0.9086331725120544, Generator Loss: 1.8335375785827637\n",
      "Epoch: 647, Discriminator Loss: 0.7010504007339478, Generator Loss: 1.861994743347168\n",
      "Epoch: 648, Discriminator Loss: 0.5990327596664429, Generator Loss: 2.1765565872192383\n",
      "Epoch: 649, Discriminator Loss: 0.5027965307235718, Generator Loss: 1.5722401142120361\n",
      "Epoch: 650, Discriminator Loss: 0.5994361639022827, Generator Loss: 1.9784058332443237\n",
      "Epoch: 651, Discriminator Loss: 0.6265961527824402, Generator Loss: 1.867234230041504\n",
      "Epoch: 652, Discriminator Loss: 0.7768390774726868, Generator Loss: 1.9253456592559814\n",
      "Epoch: 653, Discriminator Loss: 0.510481595993042, Generator Loss: 2.3214375972747803\n",
      "Epoch: 654, Discriminator Loss: 0.6483050584793091, Generator Loss: 1.9237446784973145\n",
      "Epoch: 655, Discriminator Loss: 0.4542374014854431, Generator Loss: 2.6571574211120605\n",
      "Epoch: 656, Discriminator Loss: 0.7629516124725342, Generator Loss: 1.9677014350891113\n",
      "Epoch: 657, Discriminator Loss: 0.567051887512207, Generator Loss: 2.472240924835205\n",
      "Epoch: 658, Discriminator Loss: 0.9218595027923584, Generator Loss: 1.3104875087738037\n",
      "Epoch: 659, Discriminator Loss: 0.25588899850845337, Generator Loss: 2.398977279663086\n",
      "Epoch: 660, Discriminator Loss: 0.24118193984031677, Generator Loss: 2.6065728664398193\n",
      "Epoch: 661, Discriminator Loss: 0.9871591329574585, Generator Loss: 2.3821732997894287\n",
      "Epoch: 662, Discriminator Loss: 0.7506024837493896, Generator Loss: 1.649012565612793\n",
      "Epoch: 663, Discriminator Loss: 0.4812619090080261, Generator Loss: 2.503861904144287\n",
      "Epoch: 664, Discriminator Loss: 0.3861255645751953, Generator Loss: 2.0140345096588135\n",
      "Epoch: 665, Discriminator Loss: 0.6195092797279358, Generator Loss: 1.9500025510787964\n",
      "Epoch: 666, Discriminator Loss: 0.5375751256942749, Generator Loss: 2.2667417526245117\n",
      "Epoch: 667, Discriminator Loss: 0.6583455801010132, Generator Loss: 2.2738285064697266\n",
      "Epoch: 668, Discriminator Loss: 0.624819278717041, Generator Loss: 2.403855323791504\n",
      "Epoch: 669, Discriminator Loss: 0.32545632123947144, Generator Loss: 1.840252161026001\n",
      "Epoch: 670, Discriminator Loss: 0.4091437757015228, Generator Loss: 2.1978158950805664\n",
      "Epoch: 671, Discriminator Loss: 0.449035108089447, Generator Loss: 2.3839855194091797\n",
      "Epoch: 672, Discriminator Loss: 0.7203691005706787, Generator Loss: 1.9828225374221802\n",
      "Epoch: 673, Discriminator Loss: 0.29153674840927124, Generator Loss: 2.236093282699585\n",
      "Epoch: 674, Discriminator Loss: 0.40531522035598755, Generator Loss: 2.386037826538086\n",
      "Epoch: 675, Discriminator Loss: 0.396922767162323, Generator Loss: 1.8950650691986084\n",
      "Epoch: 676, Discriminator Loss: 0.7696472406387329, Generator Loss: 1.7591891288757324\n",
      "Epoch: 677, Discriminator Loss: 0.21939435601234436, Generator Loss: 2.386434555053711\n",
      "Epoch: 678, Discriminator Loss: 0.5537234544754028, Generator Loss: 1.901318907737732\n",
      "Epoch: 679, Discriminator Loss: 0.8451449275016785, Generator Loss: 1.9883884191513062\n",
      "Epoch: 680, Discriminator Loss: 0.2886240482330322, Generator Loss: 1.9830269813537598\n",
      "Epoch: 681, Discriminator Loss: 0.42683839797973633, Generator Loss: 1.8566920757293701\n",
      "Epoch: 682, Discriminator Loss: 0.40046077966690063, Generator Loss: 2.6256182193756104\n",
      "Epoch: 683, Discriminator Loss: 0.35984891653060913, Generator Loss: 2.14923095703125\n",
      "Epoch: 684, Discriminator Loss: 0.2910739779472351, Generator Loss: 2.025085926055908\n",
      "Epoch: 685, Discriminator Loss: 0.6117699146270752, Generator Loss: 2.062108039855957\n",
      "Epoch: 686, Discriminator Loss: 0.6530579924583435, Generator Loss: 2.2483978271484375\n",
      "Epoch: 687, Discriminator Loss: 0.5124735832214355, Generator Loss: 2.405893325805664\n",
      "Epoch: 688, Discriminator Loss: 0.7592898011207581, Generator Loss: 2.1683523654937744\n",
      "Epoch: 689, Discriminator Loss: 0.631209135055542, Generator Loss: 1.6940538883209229\n",
      "Epoch: 690, Discriminator Loss: 0.3523455262184143, Generator Loss: 2.267303943634033\n",
      "Epoch: 691, Discriminator Loss: 0.4149724543094635, Generator Loss: 1.5654581785202026\n",
      "Epoch: 692, Discriminator Loss: 0.4648877680301666, Generator Loss: 2.1804795265197754\n",
      "Epoch: 693, Discriminator Loss: 0.5860744714736938, Generator Loss: 2.7248263359069824\n",
      "Epoch: 694, Discriminator Loss: 0.6244733333587646, Generator Loss: 2.3903045654296875\n",
      "Epoch: 695, Discriminator Loss: 0.3806597590446472, Generator Loss: 2.067197561264038\n",
      "Epoch: 696, Discriminator Loss: 0.49075058102607727, Generator Loss: 1.9312736988067627\n",
      "Epoch: 697, Discriminator Loss: 0.34830471873283386, Generator Loss: 2.0786619186401367\n",
      "Epoch: 698, Discriminator Loss: 0.5906946659088135, Generator Loss: 2.5138425827026367\n",
      "Epoch: 699, Discriminator Loss: 0.28649258613586426, Generator Loss: 2.523024320602417\n",
      "Epoch: 700, Discriminator Loss: 0.4249643087387085, Generator Loss: 2.570396900177002\n",
      "Epoch: 701, Discriminator Loss: 0.2551255524158478, Generator Loss: 2.056379556655884\n",
      "Epoch: 702, Discriminator Loss: 0.8162102699279785, Generator Loss: 2.156236171722412\n",
      "Epoch: 703, Discriminator Loss: 0.33499643206596375, Generator Loss: 2.3294196128845215\n",
      "Epoch: 704, Discriminator Loss: 0.47042766213417053, Generator Loss: 2.2856178283691406\n",
      "Epoch: 705, Discriminator Loss: 0.7671197652816772, Generator Loss: 1.7680354118347168\n",
      "Epoch: 706, Discriminator Loss: 0.44662994146347046, Generator Loss: 1.8304548263549805\n",
      "Epoch: 707, Discriminator Loss: 0.2975214719772339, Generator Loss: 2.079691171646118\n",
      "Epoch: 708, Discriminator Loss: 0.2239759862422943, Generator Loss: 2.6591110229492188\n",
      "Epoch: 709, Discriminator Loss: 0.2762160003185272, Generator Loss: 2.2077174186706543\n",
      "Epoch: 710, Discriminator Loss: 0.5412582159042358, Generator Loss: 1.8614234924316406\n",
      "Epoch: 711, Discriminator Loss: 0.5726357102394104, Generator Loss: 2.262556791305542\n",
      "Epoch: 712, Discriminator Loss: 0.308180570602417, Generator Loss: 1.8574516773223877\n",
      "Epoch: 713, Discriminator Loss: 0.35112354159355164, Generator Loss: 2.2975950241088867\n",
      "Epoch: 714, Discriminator Loss: 0.5237820148468018, Generator Loss: 1.827160120010376\n",
      "Epoch: 715, Discriminator Loss: 0.6839742064476013, Generator Loss: 2.1634721755981445\n",
      "Epoch: 716, Discriminator Loss: 0.3562238812446594, Generator Loss: 2.249447822570801\n",
      "Epoch: 717, Discriminator Loss: 0.24710452556610107, Generator Loss: 2.296095848083496\n",
      "Epoch: 718, Discriminator Loss: 0.5738205909729004, Generator Loss: 2.143824577331543\n",
      "Epoch: 719, Discriminator Loss: 0.24488294124603271, Generator Loss: 1.8755894899368286\n",
      "Epoch: 720, Discriminator Loss: 0.30695194005966187, Generator Loss: 1.834716796875\n",
      "Epoch: 721, Discriminator Loss: 0.32148870825767517, Generator Loss: 1.9375120401382446\n",
      "Epoch: 722, Discriminator Loss: 0.34807276725769043, Generator Loss: 2.3581981658935547\n",
      "Epoch: 723, Discriminator Loss: 0.5832293629646301, Generator Loss: 2.055874824523926\n",
      "Epoch: 724, Discriminator Loss: 0.7147662043571472, Generator Loss: 1.823988914489746\n",
      "Epoch: 725, Discriminator Loss: 0.46509402990341187, Generator Loss: 1.978782296180725\n",
      "Epoch: 726, Discriminator Loss: 0.34377723932266235, Generator Loss: 1.604742407798767\n",
      "Epoch: 727, Discriminator Loss: 0.42697978019714355, Generator Loss: 2.091708183288574\n",
      "Epoch: 728, Discriminator Loss: 0.4719839096069336, Generator Loss: 1.8165795803070068\n",
      "Epoch: 729, Discriminator Loss: 0.32141488790512085, Generator Loss: 2.485933303833008\n",
      "Epoch: 730, Discriminator Loss: 0.227000430226326, Generator Loss: 2.6836254596710205\n",
      "Epoch: 731, Discriminator Loss: 0.591374933719635, Generator Loss: 2.090546131134033\n",
      "Epoch: 732, Discriminator Loss: 0.28047975897789, Generator Loss: 2.022514581680298\n",
      "Epoch: 733, Discriminator Loss: 0.9375281929969788, Generator Loss: 1.5265425443649292\n",
      "Epoch: 734, Discriminator Loss: 0.3902168273925781, Generator Loss: 1.8702633380889893\n",
      "Epoch: 735, Discriminator Loss: 0.5174012780189514, Generator Loss: 2.1686220169067383\n",
      "Epoch: 736, Discriminator Loss: 0.3699039816856384, Generator Loss: 2.045412302017212\n",
      "Epoch: 737, Discriminator Loss: 0.356781542301178, Generator Loss: 2.3403167724609375\n",
      "Epoch: 738, Discriminator Loss: 0.5651842355728149, Generator Loss: 1.9826867580413818\n",
      "Epoch: 739, Discriminator Loss: 0.5846188068389893, Generator Loss: 2.0306077003479004\n",
      "Epoch: 740, Discriminator Loss: 0.3965798020362854, Generator Loss: 1.982583999633789\n",
      "Epoch: 741, Discriminator Loss: 0.4692009687423706, Generator Loss: 1.808716058731079\n",
      "Epoch: 742, Discriminator Loss: 0.35847705602645874, Generator Loss: 2.2286550998687744\n",
      "Epoch: 743, Discriminator Loss: 0.5854756832122803, Generator Loss: 1.9326255321502686\n",
      "Epoch: 744, Discriminator Loss: 0.5570276975631714, Generator Loss: 1.766322135925293\n",
      "Epoch: 745, Discriminator Loss: 0.3771722912788391, Generator Loss: 2.057016134262085\n",
      "Epoch: 746, Discriminator Loss: 0.6212164163589478, Generator Loss: 2.1444146633148193\n",
      "Epoch: 747, Discriminator Loss: 0.41940420866012573, Generator Loss: 2.439438819885254\n",
      "Epoch: 748, Discriminator Loss: 0.2928403615951538, Generator Loss: 2.247101068496704\n",
      "Epoch: 749, Discriminator Loss: 0.6204508543014526, Generator Loss: 2.135375499725342\n",
      "Epoch: 750, Discriminator Loss: 0.46021947264671326, Generator Loss: 2.357755184173584\n",
      "Epoch: 751, Discriminator Loss: 0.34108617901802063, Generator Loss: 1.985308051109314\n",
      "Epoch: 752, Discriminator Loss: 0.47349053621292114, Generator Loss: 1.851562738418579\n",
      "Epoch: 753, Discriminator Loss: 0.5312474966049194, Generator Loss: 2.264667510986328\n",
      "Epoch: 754, Discriminator Loss: 0.2630763053894043, Generator Loss: 2.1419928073883057\n",
      "Epoch: 755, Discriminator Loss: 0.7207887172698975, Generator Loss: 1.7299573421478271\n",
      "Epoch: 756, Discriminator Loss: 0.5945346355438232, Generator Loss: 1.5254522562026978\n",
      "Epoch: 757, Discriminator Loss: 0.526654839515686, Generator Loss: 2.0738773345947266\n",
      "Epoch: 758, Discriminator Loss: 0.49780529737472534, Generator Loss: 2.0661754608154297\n",
      "Epoch: 759, Discriminator Loss: 0.5835683345794678, Generator Loss: 2.2234716415405273\n",
      "Epoch: 760, Discriminator Loss: 0.37552598118782043, Generator Loss: 1.4807071685791016\n",
      "Epoch: 761, Discriminator Loss: 0.8217238187789917, Generator Loss: 2.4169039726257324\n",
      "Epoch: 762, Discriminator Loss: 0.4455649256706238, Generator Loss: 2.0449743270874023\n",
      "Epoch: 763, Discriminator Loss: 0.5181829929351807, Generator Loss: 1.793965220451355\n",
      "Epoch: 764, Discriminator Loss: 0.35155993700027466, Generator Loss: 1.9084312915802002\n",
      "Epoch: 765, Discriminator Loss: 0.4071415662765503, Generator Loss: 2.0266366004943848\n",
      "Epoch: 766, Discriminator Loss: 0.5029873847961426, Generator Loss: 2.218170404434204\n",
      "Epoch: 767, Discriminator Loss: 0.8988981246948242, Generator Loss: 2.1683013439178467\n",
      "Epoch: 768, Discriminator Loss: 0.3689435124397278, Generator Loss: 1.814558744430542\n",
      "Epoch: 769, Discriminator Loss: 0.5646403431892395, Generator Loss: 1.8931280374526978\n",
      "Epoch: 770, Discriminator Loss: 0.864192545413971, Generator Loss: 1.6053619384765625\n",
      "Epoch: 771, Discriminator Loss: 0.5390126705169678, Generator Loss: 1.9381929636001587\n",
      "Epoch: 772, Discriminator Loss: 0.7170562148094177, Generator Loss: 1.5899546146392822\n",
      "Epoch: 773, Discriminator Loss: 0.49159014225006104, Generator Loss: 2.566749095916748\n",
      "Epoch: 774, Discriminator Loss: 0.5110187530517578, Generator Loss: 1.709138035774231\n",
      "Epoch: 775, Discriminator Loss: 0.3980935215950012, Generator Loss: 2.315768003463745\n",
      "Epoch: 776, Discriminator Loss: 0.5695784091949463, Generator Loss: 2.10770320892334\n",
      "Epoch: 777, Discriminator Loss: 0.9228851795196533, Generator Loss: 1.7494761943817139\n",
      "Epoch: 778, Discriminator Loss: 0.3664555549621582, Generator Loss: 1.9940495491027832\n",
      "Epoch: 779, Discriminator Loss: 0.7287579774856567, Generator Loss: 1.953076958656311\n",
      "Epoch: 780, Discriminator Loss: 0.4961966574192047, Generator Loss: 2.1364822387695312\n",
      "Epoch: 781, Discriminator Loss: 0.5141583681106567, Generator Loss: 1.7326109409332275\n",
      "Epoch: 782, Discriminator Loss: 0.8735679388046265, Generator Loss: 1.6971676349639893\n",
      "Epoch: 783, Discriminator Loss: 0.3256256580352783, Generator Loss: 1.783759593963623\n",
      "Epoch: 784, Discriminator Loss: 0.5518346428871155, Generator Loss: 1.8555724620819092\n",
      "Epoch: 785, Discriminator Loss: 0.6371880769729614, Generator Loss: 1.8960962295532227\n",
      "Epoch: 786, Discriminator Loss: 0.6172256469726562, Generator Loss: 2.111926555633545\n",
      "Epoch: 787, Discriminator Loss: 0.40666478872299194, Generator Loss: 2.0549020767211914\n",
      "Epoch: 788, Discriminator Loss: 0.5966601967811584, Generator Loss: 2.3771181106567383\n",
      "Epoch: 789, Discriminator Loss: 0.570351243019104, Generator Loss: 2.018033742904663\n",
      "Epoch: 790, Discriminator Loss: 0.678729772567749, Generator Loss: 2.6244492530822754\n",
      "Epoch: 791, Discriminator Loss: 0.5586943030357361, Generator Loss: 2.1702771186828613\n",
      "Epoch: 792, Discriminator Loss: 0.423009991645813, Generator Loss: 2.236999034881592\n",
      "Epoch: 793, Discriminator Loss: 0.44692111015319824, Generator Loss: 2.035327911376953\n",
      "Epoch: 794, Discriminator Loss: 0.6107605695724487, Generator Loss: 1.9294915199279785\n",
      "Epoch: 795, Discriminator Loss: 0.48014912009239197, Generator Loss: 1.9211337566375732\n",
      "Epoch: 796, Discriminator Loss: 0.24134260416030884, Generator Loss: 2.3673930168151855\n",
      "Epoch: 797, Discriminator Loss: 0.5907173156738281, Generator Loss: 1.8314038515090942\n",
      "Epoch: 798, Discriminator Loss: 0.5868507027626038, Generator Loss: 2.521285057067871\n",
      "Epoch: 799, Discriminator Loss: 0.6999072432518005, Generator Loss: 2.403904438018799\n",
      "Epoch: 800, Discriminator Loss: 0.5300421714782715, Generator Loss: 2.305150032043457\n"
     ]
    }
   ],
   "source": [
    "train(gen,dis,train_dataset,EPOCHS,seed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
